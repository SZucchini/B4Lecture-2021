{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13e1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "bedb4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path_list):\n",
    "    load_data = (lambda path: librosa.load(path)[0])\n",
    "    data = list(map(load_data, path_list))\n",
    "    split_data = []\n",
    "    for d in data:\n",
    "        split_data.append(librosa.effects.remix(d, intervals=librosa.effects.split(d)))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0141fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data):\n",
    "    \"\"\"\n",
    "    wavファイルのリストから特徴抽出を行い，リストで返す\n",
    "    扱う特徴量はMFCC13次元の平均（0次は含めない）\n",
    "    Args:\n",
    "        path_list: 特徴抽出するファイルのパスリスト\n",
    "    Returns:\n",
    "        features: 特徴量\n",
    "    \"\"\"\n",
    "    features = np.array([np.mean(librosa.feature.mfcc(y=y, n_mfcc=20), axis=1) for y in data])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a52a5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"../../training.csv\")\n",
    "test = pd.read_csv(\"../../test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2ccf30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train_data = load(\"../../\" + training[\"path\"].values)\n",
    "test_data = load(\"../../\" + test[\"path\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "29af9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = training[\"path\"].values\n",
    "train_speaker = np.array([[path.split('/')[2].split('_')[0]] for path in train_path])\n",
    "train_speaker[train_speaker == 'jackson'] = 0\n",
    "train_speaker[train_speaker == 'nicolas'] = 1\n",
    "train_speaker[train_speaker == 'theo'] = 2\n",
    "train_speaker[train_speaker == 'yweweler'] = 3\n",
    "train_speaker[train_speaker == 'george'] = 4\n",
    "train_speaker[train_speaker == 'lucas'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b6c108de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = test[\"path\"].values\n",
    "test_speaker = np.array([[path.split('/')[2].split('_')[0]] for path in test_path])\n",
    "test_speaker[test_speaker == 'jackson'] = 0\n",
    "test_speaker[test_speaker == 'nicolas'] = 1\n",
    "test_speaker[test_speaker == 'theo'] = 2\n",
    "test_speaker[test_speaker == 'yweweler'] = 3\n",
    "test_speaker[test_speaker == 'george'] = 4\n",
    "test_speaker[test_speaker == 'lucas'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "087c44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの特徴抽出\n",
    "X_train = np.concatenate([feature_extraction(train_data), train_speaker], 1)\n",
    "X_test = np.concatenate([feature_extraction(test_data), test_speaker], 1)\n",
    "Y_train = np.array(training[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1977050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データを学習データとバリデーションデータに分割 (バリデーションセットを20%とした例)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "    X_train, Y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=20200616,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "37b01338",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "x_train = scaler.transform(X_train)\n",
    "x_valid = scaler.transform(X_valid)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(np.array(Y_train)).long()\n",
    "x_valid = torch.from_numpy(x_valid).float()\n",
    "y_valid = torch.from_numpy(np.array(Y_valid)).long()\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "91d4de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "5c71e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(21, 256)\n",
    "        self.fc2 = nn.Linear(256, 500)\n",
    "        # self.fc3 = nn.Linear(255, 255)\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "        # self.dropout1 = nn.Dropout2d(0.2)\n",
    "        # self.dropout2 = nn.Dropout2d(0.2)\n",
    "        # self.dropout3 = nn.Dropout2d(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        # x = self.dropout3(x)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "49d94de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "153b704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(net.parameters(), lr=0.98, rho=0.96)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "1932ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.1209, val_loss: 0.1048, val_acc: 0.8407\n",
      "Epoch [2/100], Loss: 0.1015, val_loss: 0.0999, val_acc: 0.8870\n",
      "Epoch [3/100], Loss: 0.0976, val_loss: 0.0999, val_acc: 0.8833\n",
      "Epoch [4/100], Loss: 0.0957, val_loss: 0.0955, val_acc: 0.9574\n",
      "Epoch [5/100], Loss: 0.0952, val_loss: 0.0957, val_acc: 0.9537\n",
      "Epoch [6/100], Loss: 0.0947, val_loss: 0.0955, val_acc: 0.9556\n",
      "Epoch [7/100], Loss: 0.0939, val_loss: 0.0948, val_acc: 0.9630\n",
      "Epoch [8/100], Loss: 0.0935, val_loss: 0.0953, val_acc: 0.9556\n",
      "Epoch [9/100], Loss: 0.0932, val_loss: 0.0946, val_acc: 0.9667\n",
      "Epoch [10/100], Loss: 0.0933, val_loss: 0.0951, val_acc: 0.9630\n",
      "Epoch [11/100], Loss: 0.0928, val_loss: 0.0945, val_acc: 0.9611\n",
      "Epoch [12/100], Loss: 0.0929, val_loss: 0.0941, val_acc: 0.9685\n",
      "Epoch [13/100], Loss: 0.0925, val_loss: 0.0946, val_acc: 0.9630\n",
      "Epoch [14/100], Loss: 0.0924, val_loss: 0.0945, val_acc: 0.9630\n",
      "Epoch [15/100], Loss: 0.0924, val_loss: 0.0938, val_acc: 0.9722\n",
      "Epoch [16/100], Loss: 0.0923, val_loss: 0.0937, val_acc: 0.9796\n",
      "Epoch [17/100], Loss: 0.0921, val_loss: 0.0942, val_acc: 0.9685\n",
      "Epoch [18/100], Loss: 0.0920, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [19/100], Loss: 0.0920, val_loss: 0.0942, val_acc: 0.9648\n",
      "Epoch [20/100], Loss: 0.0921, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [21/100], Loss: 0.0920, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [22/100], Loss: 0.0919, val_loss: 0.0933, val_acc: 0.9852\n",
      "Epoch [23/100], Loss: 0.0919, val_loss: 0.0938, val_acc: 0.9722\n",
      "Epoch [24/100], Loss: 0.0918, val_loss: 0.0938, val_acc: 0.9741\n",
      "Epoch [25/100], Loss: 0.0918, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [26/100], Loss: 0.0918, val_loss: 0.0938, val_acc: 0.9704\n",
      "Epoch [27/100], Loss: 0.0918, val_loss: 0.0934, val_acc: 0.9778\n",
      "Epoch [28/100], Loss: 0.0917, val_loss: 0.0941, val_acc: 0.9685\n",
      "Epoch [29/100], Loss: 0.0918, val_loss: 0.0935, val_acc: 0.9778\n",
      "Epoch [30/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9722\n",
      "Epoch [31/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9722\n",
      "Epoch [32/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9759\n",
      "Epoch [33/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [34/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [35/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [36/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9741\n",
      "Epoch [37/100], Loss: 0.0917, val_loss: 0.0938, val_acc: 0.9722\n",
      "Epoch [38/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9759\n",
      "Epoch [39/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [40/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9741\n",
      "Epoch [41/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [42/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [43/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [44/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [45/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9741\n",
      "Epoch [46/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [47/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9741\n",
      "Epoch [48/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9759\n",
      "Epoch [49/100], Loss: 0.0917, val_loss: 0.0935, val_acc: 0.9778\n",
      "Epoch [50/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9741\n",
      "Epoch [51/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [52/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9759\n",
      "Epoch [53/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9741\n",
      "Epoch [54/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9741\n",
      "Epoch [55/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [56/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9741\n",
      "Epoch [57/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [58/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9741\n",
      "Epoch [59/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [60/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [61/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [62/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [63/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9741\n",
      "Epoch [64/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [65/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [66/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [67/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [68/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [69/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [70/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [71/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [72/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [73/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [74/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [75/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [76/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [77/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [78/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [79/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [80/100], Loss: 0.0917, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [81/100], Loss: 0.0917, val_loss: 0.0937, val_acc: 0.9778\n",
      "Epoch [82/100], Loss: 0.0916, val_loss: 0.0935, val_acc: 0.9778\n",
      "Epoch [83/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [84/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [85/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [86/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [87/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [88/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [89/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [90/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [91/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [92/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [93/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [94/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9759\n",
      "Epoch [95/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [96/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [97/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [98/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [99/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n",
      "Epoch [100/100], Loss: 0.0916, val_loss: 0.0936, val_acc: 0.9778\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
    " \n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc = 0, 0, 0, 0\n",
    "    \n",
    "    net.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        acc = (outputs.max(1)[1] == labels).sum()\n",
    "        train_acc += acc.item()\n",
    "        loss.backward()      \n",
    "        optimizer.step()\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in valid_loader:        \n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = net(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          val_loss += loss.item()\n",
    "          acc = (outputs.max(1)[1] == labels).sum()\n",
    "          val_acc += acc.item()\n",
    "    avg_val_loss = val_loss / len(valid_loader.dataset)\n",
    "    avg_val_acc = val_acc / len(valid_loader.dataset)\n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}' \n",
    "                   .format(epoch+1, epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n",
    " \n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    train_acc_list.append(avg_train_acc)\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    val_acc_list.append(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "41083a8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (200,) and (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-968a055ea3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/b4lec/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/miniforge3/envs/b4lec/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/b4lec/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/b4lec/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (100,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(1, 201)]\n",
    "plt.plot(x, train_acc_list)\n",
    "plt.plot(x, val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a95dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, train_loss_list)\n",
    "plt.plot(x, val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3acbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(X_test)\n",
    "x_test = torch.from_numpy(x_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3512953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "838d4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = outputs.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a0a80928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 3, 3, 3, 3,\n",
       "        3, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 1, 1, 4,\n",
       "        1, 1, 8, 8, 8, 8, 8, 3, 9, 9, 9, 9, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 0, 0,\n",
       "        0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7,\n",
       "        7, 7, 7, 7, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 7, 7, 7, 9, 7, 3, 3, 3, 3,\n",
       "        3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 0, 0, 0,\n",
       "        0, 0, 2, 2, 2, 2, 2, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3, 3,\n",
       "        6, 3, 3, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 6, 6, 6, 3, 6, 7, 7, 7, 7, 7, 8,\n",
       "        8, 8, 8, 8, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "        1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 7, 7, 7, 2, 7, 6, 6, 6, 6,\n",
       "        6, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 1, 1, 1, 7, 1, 5, 5, 5, 5, 5, 8, 8, 8,\n",
       "        8, 8, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
