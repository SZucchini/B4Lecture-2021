{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e13e1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bedb4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path_list):\n",
    "    load_data = (lambda path: librosa.load(path)[0])\n",
    "    data = list(map(load_data, path_list))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0141fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data):\n",
    "    \"\"\"\n",
    "    wavファイルのリストから特徴抽出を行い，リストで返す\n",
    "    扱う特徴量はMFCC13次元の平均（0次は含めない）\n",
    "    Args:\n",
    "        path_list: 特徴抽出するファイルのパスリスト\n",
    "    Returns:\n",
    "        features: 特徴量\n",
    "    \"\"\"\n",
    "    features = np.array([np.mean(librosa.feature.mfcc(y=y, n_mfcc=20), axis=1) for y in data])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a52a5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"../training.csv\")\n",
    "test = pd.read_csv(\"../test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ccf30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train_data = load(\"../\" + training[\"path\"].values)\n",
    "test_data = load(\"../\" + test[\"path\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "087c44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの特徴抽出\n",
    "X_train = feature_extraction(train_data)\n",
    "X_test = feature_extraction(test_data)\n",
    "Y_train = np.array(training[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1977050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データを学習データとバリデーションデータに分割 (バリデーションセットを20%とした例)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "    X_train, Y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=20200616,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37b01338",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "x_train = scaler.transform(X_train)\n",
    "x_valid = scaler.transform(X_valid)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(np.array(Y_train)).long()\n",
    "x_valid = torch.from_numpy(x_valid).float()\n",
    "y_valid = torch.from_numpy(np.array(Y_valid)).long()\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "91d4de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5c71e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 255)\n",
    "        self.fc2 = nn.Linear(255, 255)\n",
    "        # self.fc3 = nn.Linear(255, 255)\n",
    "        self.fc3 = nn.Linear(255, 10)\n",
    "        # self.dropout1 = nn.Dropout2d(0.2)\n",
    "        # self.dropout2 = nn.Dropout2d(0.2)\n",
    "        # self.dropout3 = nn.Dropout2d(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        # x = self.dropout3(x)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "49d94de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "153b704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(net.parameters(), lr=1)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1932ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.4580, val_loss: 0.4042, val_acc: 0.8574\n",
      "Epoch [2/100], Loss: 0.3990, val_loss: 0.3919, val_acc: 0.9037\n",
      "Epoch [3/100], Loss: 0.3882, val_loss: 0.3869, val_acc: 0.9185\n",
      "Epoch [4/100], Loss: 0.3833, val_loss: 0.3788, val_acc: 0.9481\n",
      "Epoch [5/100], Loss: 0.3797, val_loss: 0.3778, val_acc: 0.9556\n",
      "Epoch [6/100], Loss: 0.3771, val_loss: 0.3772, val_acc: 0.9611\n",
      "Epoch [7/100], Loss: 0.3767, val_loss: 0.3778, val_acc: 0.9500\n",
      "Epoch [8/100], Loss: 0.3749, val_loss: 0.3762, val_acc: 0.9611\n",
      "Epoch [9/100], Loss: 0.3733, val_loss: 0.3736, val_acc: 0.9704\n",
      "Epoch [10/100], Loss: 0.3733, val_loss: 0.3756, val_acc: 0.9593\n",
      "Epoch [11/100], Loss: 0.3716, val_loss: 0.3796, val_acc: 0.9481\n",
      "Epoch [12/100], Loss: 0.3717, val_loss: 0.3725, val_acc: 0.9778\n",
      "Epoch [13/100], Loss: 0.3711, val_loss: 0.3731, val_acc: 0.9741\n",
      "Epoch [14/100], Loss: 0.3704, val_loss: 0.3730, val_acc: 0.9722\n",
      "Epoch [15/100], Loss: 0.3698, val_loss: 0.3728, val_acc: 0.9685\n",
      "Epoch [16/100], Loss: 0.3690, val_loss: 0.3730, val_acc: 0.9685\n",
      "Epoch [17/100], Loss: 0.3685, val_loss: 0.3735, val_acc: 0.9704\n",
      "Epoch [18/100], Loss: 0.3684, val_loss: 0.3738, val_acc: 0.9630\n",
      "Epoch [19/100], Loss: 0.3681, val_loss: 0.3726, val_acc: 0.9722\n",
      "Epoch [20/100], Loss: 0.3679, val_loss: 0.3721, val_acc: 0.9741\n",
      "Epoch [21/100], Loss: 0.3677, val_loss: 0.3769, val_acc: 0.9537\n",
      "Epoch [22/100], Loss: 0.3677, val_loss: 0.3724, val_acc: 0.9704\n",
      "Epoch [23/100], Loss: 0.3677, val_loss: 0.3725, val_acc: 0.9722\n",
      "Epoch [24/100], Loss: 0.3674, val_loss: 0.3723, val_acc: 0.9722\n",
      "Epoch [25/100], Loss: 0.3674, val_loss: 0.3726, val_acc: 0.9704\n",
      "Epoch [26/100], Loss: 0.3672, val_loss: 0.3718, val_acc: 0.9741\n",
      "Epoch [27/100], Loss: 0.3674, val_loss: 0.3721, val_acc: 0.9741\n",
      "Epoch [28/100], Loss: 0.3672, val_loss: 0.3728, val_acc: 0.9722\n",
      "Epoch [29/100], Loss: 0.3673, val_loss: 0.3714, val_acc: 0.9778\n",
      "Epoch [30/100], Loss: 0.3673, val_loss: 0.3713, val_acc: 0.9796\n",
      "Epoch [31/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9778\n",
      "Epoch [32/100], Loss: 0.3673, val_loss: 0.3718, val_acc: 0.9759\n",
      "Epoch [33/100], Loss: 0.3673, val_loss: 0.3716, val_acc: 0.9741\n",
      "Epoch [34/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9759\n",
      "Epoch [35/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [36/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9759\n",
      "Epoch [37/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9741\n",
      "Epoch [38/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9778\n",
      "Epoch [39/100], Loss: 0.3671, val_loss: 0.3711, val_acc: 0.9778\n",
      "Epoch [40/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [41/100], Loss: 0.3671, val_loss: 0.3711, val_acc: 0.9778\n",
      "Epoch [42/100], Loss: 0.3671, val_loss: 0.3715, val_acc: 0.9741\n",
      "Epoch [43/100], Loss: 0.3671, val_loss: 0.3718, val_acc: 0.9722\n",
      "Epoch [44/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [45/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9759\n",
      "Epoch [46/100], Loss: 0.3671, val_loss: 0.3719, val_acc: 0.9741\n",
      "Epoch [47/100], Loss: 0.3671, val_loss: 0.3718, val_acc: 0.9722\n",
      "Epoch [48/100], Loss: 0.3671, val_loss: 0.3718, val_acc: 0.9741\n",
      "Epoch [49/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [50/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9759\n",
      "Epoch [51/100], Loss: 0.3671, val_loss: 0.3717, val_acc: 0.9722\n",
      "Epoch [52/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9741\n",
      "Epoch [53/100], Loss: 0.3671, val_loss: 0.3717, val_acc: 0.9722\n",
      "Epoch [54/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [55/100], Loss: 0.3671, val_loss: 0.3710, val_acc: 0.9796\n",
      "Epoch [56/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9741\n",
      "Epoch [57/100], Loss: 0.3671, val_loss: 0.3717, val_acc: 0.9741\n",
      "Epoch [58/100], Loss: 0.3671, val_loss: 0.3711, val_acc: 0.9759\n",
      "Epoch [59/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9741\n",
      "Epoch [60/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9741\n",
      "Epoch [61/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9778\n",
      "Epoch [62/100], Loss: 0.3671, val_loss: 0.3721, val_acc: 0.9741\n",
      "Epoch [63/100], Loss: 0.3671, val_loss: 0.3709, val_acc: 0.9778\n",
      "Epoch [64/100], Loss: 0.3671, val_loss: 0.3720, val_acc: 0.9722\n",
      "Epoch [65/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9759\n",
      "Epoch [66/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9759\n",
      "Epoch [67/100], Loss: 0.3671, val_loss: 0.3723, val_acc: 0.9704\n",
      "Epoch [68/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9778\n",
      "Epoch [69/100], Loss: 0.3671, val_loss: 0.3722, val_acc: 0.9704\n",
      "Epoch [70/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [71/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9741\n",
      "Epoch [72/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9759\n",
      "Epoch [73/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9759\n",
      "Epoch [74/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9759\n",
      "Epoch [75/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9741\n",
      "Epoch [76/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9741\n",
      "Epoch [77/100], Loss: 0.3671, val_loss: 0.3719, val_acc: 0.9704\n",
      "Epoch [78/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [79/100], Loss: 0.3671, val_loss: 0.3720, val_acc: 0.9722\n",
      "Epoch [80/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9759\n",
      "Epoch [81/100], Loss: 0.3671, val_loss: 0.3717, val_acc: 0.9759\n",
      "Epoch [82/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9741\n",
      "Epoch [83/100], Loss: 0.3672, val_loss: 0.3710, val_acc: 0.9778\n",
      "Epoch [84/100], Loss: 0.3671, val_loss: 0.3707, val_acc: 0.9796\n",
      "Epoch [85/100], Loss: 0.3671, val_loss: 0.3709, val_acc: 0.9778\n",
      "Epoch [86/100], Loss: 0.3671, val_loss: 0.3711, val_acc: 0.9778\n",
      "Epoch [87/100], Loss: 0.3671, val_loss: 0.3713, val_acc: 0.9759\n",
      "Epoch [88/100], Loss: 0.3671, val_loss: 0.3711, val_acc: 0.9778\n",
      "Epoch [89/100], Loss: 0.3671, val_loss: 0.3711, val_acc: 0.9741\n",
      "Epoch [90/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9778\n",
      "Epoch [91/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9759\n",
      "Epoch [92/100], Loss: 0.3671, val_loss: 0.3717, val_acc: 0.9741\n",
      "Epoch [93/100], Loss: 0.3671, val_loss: 0.3714, val_acc: 0.9759\n",
      "Epoch [94/100], Loss: 0.3671, val_loss: 0.3716, val_acc: 0.9722\n",
      "Epoch [95/100], Loss: 0.3671, val_loss: 0.3712, val_acc: 0.9759\n",
      "Epoch [96/100], Loss: 0.3671, val_loss: 0.3715, val_acc: 0.9741\n",
      "Epoch [97/100], Loss: 0.3671, val_loss: 0.3720, val_acc: 0.9722\n",
      "Epoch [98/100], Loss: 0.3671, val_loss: 0.3708, val_acc: 0.9796\n",
      "Epoch [99/100], Loss: 0.3671, val_loss: 0.3721, val_acc: 0.9722\n",
      "Epoch [100/100], Loss: 0.3671, val_loss: 0.3709, val_acc: 0.9778\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
    " \n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc = 0, 0, 0, 0\n",
    "    \n",
    "    net.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        acc = (outputs.max(1)[1] == labels).sum()\n",
    "        train_acc += acc.item()\n",
    "        loss.backward()      \n",
    "        optimizer.step()\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in valid_loader:        \n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = net(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          val_loss += loss.item()\n",
    "          acc = (outputs.max(1)[1] == labels).sum()\n",
    "          val_acc += acc.item()\n",
    "    avg_val_loss = val_loss / len(valid_loader.dataset)\n",
    "    avg_val_acc = val_acc / len(valid_loader.dataset)\n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}' \n",
    "                   .format(epoch+1, epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n",
    " \n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    train_acc_list.append(avg_train_acc)\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    val_acc_list.append(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41083a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, 201)]\n",
    "plt.plot(x, train_acc_list)\n",
    "plt.plot(x, val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a95dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, train_loss_list)\n",
    "plt.plot(x, val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3acbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(X_test)\n",
    "x_test = torch.from_numpy(x_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3512953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "838d4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = outputs.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a0a80928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 3, 3, 3, 3,\n",
       "        3, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 1, 1, 4,\n",
       "        1, 1, 8, 8, 8, 8, 8, 3, 9, 9, 9, 9, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 0, 0,\n",
       "        0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7,\n",
       "        7, 7, 7, 7, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 7, 7, 7, 9, 7, 3, 3, 3, 3,\n",
       "        3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 0, 0, 0,\n",
       "        0, 0, 2, 2, 2, 2, 2, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3, 3,\n",
       "        6, 3, 3, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 6, 6, 6, 3, 6, 7, 7, 7, 7, 7, 8,\n",
       "        8, 8, 8, 8, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "        1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 7, 7, 7, 2, 7, 6, 6, 6, 6,\n",
       "        6, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 1, 1, 1, 7, 1, 5, 5, 5, 5, 5, 8, 8, 8,\n",
       "        8, 8, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
